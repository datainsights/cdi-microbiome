{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61216e47",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# (PART) MACHINE LEARNING {-}\n",
    "\n",
    "# How do you  prepare microbiome data for machine learning?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Before applying machine learning, you must structure your OTU table and metadata into a form suitable for modeling.\n",
    "\n",
    "Typical steps include:\n",
    "- **Filtering**: Keep relevant OTUs/features\n",
    "- **Merging**: Align OTU table with sample metadata\n",
    "- **Encoding**: Set up group labels (e.g., Control = 0, Treatment = 1)\n",
    "- **Splitting**: Train-test split to evaluate generalizability\n",
    "\n",
    "This Q&A sets up data for classification.\n",
    "\n",
    "## Python Code\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "otu_df = pd.read_csv(\"data/otu_table_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "meta_df = pd.read_csv(\"data/sample_metadata.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Merge OTU table with metadata by sample\n",
    "data = pd.merge(otu_df, meta_df, left_index=True, right_on=\"sample_id\")\n",
    "\n",
    "# Define features (X) and labels (y)\n",
    "X = data[otu_df.columns]  # OTU features\n",
    "y = data[\"group\"].map({\"Control\": 0, \"Treatment\": 1})  # binary encoding\n",
    "\n",
    "# Split into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check shape\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "```\n",
    "\n",
    "## R Note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most ML pipelines in microbiome analysis are performed in Python.\n",
    "# In R, similar workflows can be built using caret, tidymodels, or mlr3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c072c8ab",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# How do you  train and evaluate a Random Forest classifier on microbiome data?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "The **Random Forest** algorithm is a popular and robust model for microbiome classification tasks due to its:\n",
    "- Built-in feature importance\n",
    "- Resistance to overfitting\n",
    "- Non-linear modeling capability\n",
    "\n",
    "This Q&A demonstrates how to:\n",
    "- Train a Random Forest classifier\n",
    "- Evaluate it using accuracy and confusion matrix\n",
    "- Inspect important OTUs\n",
    "\n",
    "## Python Code\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare data\n",
    "otu_df = pd.read_csv(\"data/otu_table_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "meta_df = pd.read_csv(\"data/sample_metadata.tsv\", sep=\"\\t\")\n",
    "data = pd.merge(otu_df, meta_df, left_index=True, right_on=\"sample_id\")\n",
    "X = data[otu_df.columns]\n",
    "y = data[\"group\"].map({\"Control\": 0, \"Treatment\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Top 5 important OTUs\n",
    "feat_imp = pd.Series(clf.feature_importances_, index=X.columns)\n",
    "print(\"Top OTUs:\n",
    "\", feat_imp.sort_values(ascending=False).head())\n",
    "```\n",
    "\n",
    "## R Code (caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "\n",
    "otu_df <- read.delim(\"data/otu_table_filtered.tsv\", row.names = 1)\n",
    "meta_df <- read.delim(\"data/sample_metadata.tsv\")\n",
    "otu_df <- otu_df[, meta_df$sample_id]\n",
    "otu_df <- t(otu_df)\n",
    "data <- cbind(as.data.frame(otu_df), group = meta_df$group)\n",
    "\n",
    "# Encode group and split\n",
    "data$group <- as.factor(data$group)\n",
    "set.seed(42)\n",
    "trainIndex <- createDataPartition(data$group, p = .7, list = FALSE)\n",
    "train <- data[trainIndex, ]\n",
    "test  <- data[-trainIndex, ]\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model <- train(group ~ ., data = train, method = \"rf\", trControl = trainControl(method = \"cv\", number = 5))\n",
    "\n",
    "# Predict and evaluate\n",
    "pred <- predict(rf_model, newdata = test)\n",
    "confusionMatrix(pred, test$group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a0c62",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# How do you  build a Logistic Regression model for microbiome classification?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "**Logistic Regression** is a foundational classification model useful for:\n",
    "- Binary prediction (e.g., Control vs Treatment)\n",
    "- Interpreting OTU effects via coefficients\n",
    "- Establishing baselines before more complex models\n",
    "\n",
    "This Q&A shows how to train and evaluate a Logistic Regression model.\n",
    "\n",
    "## Python Code\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare data\n",
    "otu_df = pd.read_csv(\"data/otu_table_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "meta_df = pd.read_csv(\"data/sample_metadata.tsv\", sep=\"\\t\")\n",
    "data = pd.merge(otu_df, meta_df, left_index=True, right_on=\"sample_id\")\n",
    "X = data[otu_df.columns]\n",
    "y = data[\"group\"].map({\"Control\": 0, \"Treatment\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Inspect top OTUs by absolute coefficient magnitude\n",
    "coef = pd.Series(model.coef_[0], index=X.columns)\n",
    "print(\"Top OTUs:\n",
    "\", coef.abs().sort_values(ascending=False).head())\n",
    "```\n",
    "\n",
    "## R Code (caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "\n",
    "otu_df <- read.delim(\"data/otu_table_filtered.tsv\", row.names = 1)\n",
    "meta_df <- read.delim(\"data/sample_metadata.tsv\")\n",
    "otu_df <- otu_df[, meta_df$sample_id]\n",
    "otu_df <- t(otu_df)\n",
    "data <- cbind(as.data.frame(otu_df), group = meta_df$group)\n",
    "\n",
    "# Encode group and split\n",
    "data$group <- as.factor(data$group)\n",
    "set.seed(42)\n",
    "trainIndex <- createDataPartition(data$group, p = .7, list = FALSE)\n",
    "train <- data[trainIndex, ]\n",
    "test  <- data[-trainIndex, ]\n",
    "\n",
    "# Train logistic regression\n",
    "lr_model <- train(group ~ ., data = train, method = \"glm\", family = \"binomial\", trControl = trainControl(method = \"cv\", number = 5))\n",
    "\n",
    "# Predict and evaluate\n",
    "pred <- predict(lr_model, newdata = test)\n",
    "confusionMatrix(pred, test$group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a340411e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# How do you  train a Support Vector Machine (SVM) for microbiome classification?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "**Support Vector Machines (SVM)** are powerful classifiers for high-dimensional biological data. They find a decision boundary (hyperplane) that maximizes class separation.\n",
    "\n",
    "SVMs are well-suited for microbiome data because:\n",
    "- They can handle many features (OTUs)\n",
    "- Work with kernel functions for non-linear separation\n",
    "- Often perform well with sparse data\n",
    "\n",
    "## Python Code\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare data\n",
    "otu_df = pd.read_csv(\"data/otu_table_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "meta_df = pd.read_csv(\"data/sample_metadata.tsv\", sep=\"\\t\")\n",
    "data = pd.merge(otu_df, meta_df, left_index=True, right_on=\"sample_id\")\n",
    "X = data[otu_df.columns]\n",
    "y = data[\"group\"].map({\"Control\": 0, \"Treatment\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train SVM\n",
    "model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "```\n",
    "\n",
    "## R Code (caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "\n",
    "otu_df <- read.delim(\"data/otu_table_filtered.tsv\", row.names = 1)\n",
    "meta_df <- read.delim(\"data/sample_metadata.tsv\")\n",
    "otu_df <- otu_df[, meta_df$sample_id]\n",
    "otu_df <- t(otu_df)\n",
    "data <- cbind(as.data.frame(otu_df), group = meta_df$group)\n",
    "\n",
    "# Encode group and split\n",
    "data$group <- as.factor(data$group)\n",
    "set.seed(42)\n",
    "trainIndex <- createDataPartition(data$group, p = .7, list = FALSE)\n",
    "train <- data[trainIndex, ]\n",
    "test  <- data[-trainIndex, ]\n",
    "\n",
    "# Train SVM\n",
    "svm_model <- train(group ~ ., data = train, method = \"svmLinear\", trControl = trainControl(method = \"cv\", number = 5))\n",
    "\n",
    "# Predict and evaluate\n",
    "pred <- predict(svm_model, newdata = test)\n",
    "confusionMatrix(pred, test$group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f6e56",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# How do you  apply Gradient Boosting (XGBoost) for microbiome classification?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "**XGBoost** is an efficient, scalable gradient boosting algorithm widely used in biological classification tasks. It's known for:\n",
    "- High performance on structured/tabular data\n",
    "- Handling of missing values\n",
    "- Built-in feature importance metrics\n",
    "\n",
    "This Q&A shows how to train and evaluate an XGBoost classifier.\n",
    "\n",
    "## Python Code\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare data\n",
    "otu_df = pd.read_csv(\"data/otu_table_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "meta_df = pd.read_csv(\"data/sample_metadata.tsv\", sep=\"\\t\")\n",
    "data = pd.merge(otu_df, meta_df, left_index=True, right_on=\"sample_id\")\n",
    "X = data[otu_df.columns]\n",
    "y = data[\"group\"].map({\"Control\": 0, \"Treatment\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train XGBoost classifier\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Top important OTUs\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "print(\"Top Features:\n",
    "\", importances.sort_values(ascending=False).head())\n",
    "```\n",
    "\n",
    "## R Code (caret + xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fa123",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "library(xgboost)\n",
    "\n",
    "otu_df <- read.delim(\"data/otu_table_filtered.tsv\", row.names = 1)\n",
    "meta_df <- read.delim(\"data/sample_metadata.tsv\")\n",
    "otu_df <- otu_df[, meta_df$sample_id]\n",
    "otu_df <- t(otu_df)\n",
    "data <- cbind(as.data.frame(otu_df), group = meta_df$group)\n",
    "\n",
    "# Encode group and split\n",
    "data$group <- as.factor(data$group)\n",
    "set.seed(42)\n",
    "trainIndex <- createDataPartition(data$group, p = .7, list = FALSE)\n",
    "train <- data[trainIndex, ]\n",
    "test  <- data[-trainIndex, ]\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model <- train(group ~ ., data = train, method = \"xgbTree\", trControl = trainControl(method = \"cv\", number = 5))\n",
    "\n",
    "# Predict and evaluate\n",
    "pred <- predict(xgb_model, newdata = test)\n",
    "confusionMatrix(pred, test$group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50302a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# How do you  visualize ROC curves to compare classification models?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "**Receiver Operating Characteristic (ROC) curves** help visualize model performance across different thresholds. The **Area Under the Curve (AUC)** summarizes performance â€” closer to 1.0 is better.\n",
    "\n",
    "Comparing ROC curves across models (e.g., Random Forest, Logistic Regression, XGBoost) provides insight into which performs best and where they differ.\n",
    "\n",
    "This Q&A demonstrates ROC curve generation in Python and R.\n",
    "\n",
    "## Python Code\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data\n",
    "otu_df = pd.read_csv(\"data/otu_table_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "meta_df = pd.read_csv(\"data/sample_metadata.tsv\", sep=\"\\t\")\n",
    "data = pd.merge(otu_df, meta_df, left_index=True, right_on=\"sample_id\")\n",
    "X = data[otu_df.columns]\n",
    "y = data[\"group\"].map({\"Control\": 0, \"Treatment\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    probas = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, probas)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## R Code (caret + pROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df999936",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "library(pROC)\n",
    "\n",
    "otu_df <- read.delim(\"data/otu_table_filtered.tsv\", row.names = 1)\n",
    "meta_df <- read.delim(\"data/sample_metadata.tsv\")\n",
    "otu_df <- otu_df[, meta_df$sample_id]\n",
    "otu_df <- t(otu_df)\n",
    "data <- cbind(as.data.frame(otu_df), group = as.factor(meta_df$group))\n",
    "\n",
    "# Train/test split\n",
    "set.seed(42)\n",
    "trainIndex <- createDataPartition(data$group, p = .7, list = FALSE)\n",
    "train <- data[trainIndex, ]\n",
    "test  <- data[-trainIndex, ]\n",
    "\n",
    "# Define fixed tuning for models that require it\n",
    "rf_grid <- data.frame(mtry = floor(sqrt(ncol(train) - 1)))\n",
    "svm_grid <- data.frame(C = 1)\n",
    "xgb_grid <- data.frame(\n",
    "  nrounds = 50,\n",
    "  max_depth = 3,\n",
    "  eta = 0.3,\n",
    "  gamma = 0,\n",
    "  colsample_bytree = 1,\n",
    "  min_child_weight = 1,\n",
    "  subsample = 1\n",
    ")\n",
    "\n",
    "# Train models using fixed tuneGrid\n",
    "models <- list(\n",
    "  rf = train(group ~ ., data = train, method = \"rf\", trControl = trainControl(method = \"none\"), tuneGrid = rf_grid),\n",
    "  glm = train(group ~ ., data = train, method = \"glm\", family = \"binomial\", trControl = trainControl(method = \"none\")),\n",
    "  svm = train(group ~ ., data = train, method = \"svmLinear\", trControl = trainControl(method = \"none\"), tuneGrid = svm_grid),\n",
    "  xgb = train(group ~ ., data = train, method = \"xgbTree\", trControl = trainControl(method = \"none\"), tuneGrid = xgb_grid)\n",
    ")\n",
    "\n",
    "# ROC analysis\n",
    "roc_list <- lapply(models, function(model) {\n",
    "  probs <- predict(model, newdata = test, type = \"prob\")\n",
    "  # Safely extract numeric probabilities for the \"Treatment\" class\n",
    "  class_label <- \"Treatment\"\n",
    "  if (!(class_label %in% colnames(probs))) {\n",
    "    stop(paste(\"Class label\", class_label, \"not found in predicted probabilities\"))\n",
    "  }\n",
    "  prob_values <- as.numeric(probs[, class_label])\n",
    "  roc(response = test$group, predictor = prob_values)\n",
    "})\n",
    "\n",
    "# Plot ROC\n",
    "plot(roc_list[[1]], col = \"blue\", legacy.axes = TRUE, main = \"ROC Curves - Microbiome Classification\")\n",
    "cols <- c(\"blue\", \"green\", \"red\", \"purple\")\n",
    "for (i in 2:length(roc_list)) {\n",
    "  plot(roc_list[[i]], col = cols[i], add = TRUE)\n",
    "}\n",
    "legend(\"bottomright\", legend = names(models), col = cols, lwd = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531308e5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# How do you  apply cross-validation strategies to evaluate model reliability?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "**Cross-validation (CV)** is critical for evaluating how well a machine learning model generalizes to unseen data. It reduces the risk of overfitting by testing the model on multiple train/test splits.\n",
    "\n",
    "Common CV strategies:\n",
    "- **k-Fold**: Split into k subsets, rotate test set\n",
    "- **Repeated k-Fold**: More robust by repeating k-fold several times\n",
    "- **Stratified k-Fold**: Ensures balanced class distribution in folds\n",
    "\n",
    "This Q&A shows how to apply CV in Python and R using common microbiome classifiers.\n",
    "\n",
    "## Python Code\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Load and prepare data\n",
    "otu_df = pd.read_csv(\"data/otu_table_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "meta_df = pd.read_csv(\"data/sample_metadata.tsv\", sep=\"\\t\")\n",
    "data = pd.merge(otu_df, meta_df, left_index=True, right_on=\"sample_id\")\n",
    "X = data[otu_df.columns]\n",
    "y = data[\"group\"].map({\"Control\": 0, \"Treatment\": 1})\n",
    "\n",
    "# Define CV strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate Random Forest using cross-validation\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "```\n",
    "\n",
    "## R Code (caret with repeated k-fold CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(caret)\n",
    "\n",
    "otu_df <- read.delim(\"data/otu_table_filtered.tsv\", row.names = 1)\n",
    "meta_df <- read.delim(\"data/sample_metadata.tsv\")\n",
    "otu_df <- otu_df[, meta_df$sample_id]\n",
    "otu_df <- t(otu_df)\n",
    "data <- cbind(as.data.frame(otu_df), group = as.factor(meta_df$group))\n",
    "\n",
    "# Define CV control\n",
    "ctrl <- trainControl(method = \"repeatedcv\", number = 5, repeats = 3)\n",
    "\n",
    "# Train with CV\n",
    "set.seed(42)\n",
    "cv_model <- train(group ~ ., data = data, method = \"rf\", trControl = ctrl)\n",
    "\n",
    "# Results\n",
    "print(cv_model)\n",
    "plot(cv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372ec29",
   "metadata": {},
   "source": [
    "# How do you  use `mikropml` in R for microbiome machine learning?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "[`mikropml`](https://github.com/SchlossLab/mikropml) is a microbiome-focused R package by Pat Schloss designed for:\n",
    "- End-to-end modeling workflows\n",
    "- Built-in cross-validation and hyperparameter tuning\n",
    "- Transparency in model reporting and evaluation\n",
    "\n",
    "It simplifies the process of building, tuning, and interpreting microbiome ML models.\n",
    "\n",
    "This Q&A introduces a basic pipeline using `mikropml` and prepares the OTU and metadata files as expected.\n",
    "\n",
    "## R Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Ensure mikropml is installed\n",
    "if (!requireNamespace(\"mikropml\", quietly = TRUE)) {\n",
    "  if (!requireNamespace(\"remotes\", quietly = TRUE)) install.packages(\"remotes\")\n",
    "  remotes::install_github(\"SchlossLab/mikropml\")\n",
    "}\n",
    "\n",
    "library(mikropml)\n",
    "library(tidyverse)\n",
    "\n",
    "# Load OTU table and metadata\n",
    "otu <- read.delim(\"data/otu_table_filtered.tsv\", row.names = 1)\n",
    "meta <- read.delim(\"data/sample_metadata.tsv\")\n",
    "\n",
    "# Transpose OTU so samples are rows\n",
    "otu_t <- t(otu)\n",
    "otu_df <- as.data.frame(otu_t)\n",
    "otu_df$sample_id <- rownames(otu_t)\n",
    "\n",
    "# Merge with metadata\n",
    "data <- inner_join(otu_df, meta, by = \"sample_id\")\n",
    "\n",
    "# Run mikropml using run_ml()\n",
    "set.seed(42)\n",
    "fit <- run_ml(\n",
    "  dataset = data,\n",
    "  outcome_colname = \"group\",\n",
    "  method = \"rf\",        # Choose from rf, svm, glmnet, xgb\n",
    "  seed = 42\n",
    ")\n",
    "\n",
    "# View model summary\n",
    "summary(fit)\n",
    "\n",
    "# Plot variable importance\n",
    "fit$importance_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54404be7",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- mikropl supports additional tuning and export for reproducibility.\n",
    "- `mikropml()` auto-detects classification vs regression tasks."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "eval,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
