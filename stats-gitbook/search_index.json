[["index.html", "Microbiome Statistical Analysis ", " Microbiome Statistical Analysis Last updated: May 26, 2025 "],["what-are-the-essential-tools-for-microbiome-read-quality-control.html", "Q&A 1 What are the essential tools for microbiome read quality control? 1.1 Explanation 1.2 Shell Code 1.3 R Note", " Q&A 1 What are the essential tools for microbiome read quality control? 1.1 Explanation Every microbiome analysis begins with raw sequencing data, often in the form of FASTQ files. These files contain both the nucleotide reads and quality scores. However, raw reads are rarely perfect — they may contain adapter sequences, low-quality regions, or even contaminant DNA. Before proceeding to any taxonomic or functional profiling, it’s essential to clean and assess these reads. This is the foundation of your analysis pipeline — ensuring that only high-quality data moves forward. Several tools have been developed for this exact purpose. Most are installable via Bioconda, and they can be used independently or as part of an automated pipeline. Here’s a breakdown of what each tool does: Seqkit: Provides basic statistics about your FASTQ files (e.g., length distribution, GC content). FastQC: Generates per-base quality score plots to detect poor-quality cycles. MultiQC: Aggregates FastQC outputs across samples into a single report. BBMap / Trimmomatic: Trim adapters, remove artifacts, and perform quality filtering. Kneaddata: Specialized for metagenomics, it removes contaminant reads (e.g., host DNA) using alignment-based filtering. 1.2 Shell Code # Install individual tools using mamba and bioconda mamba install -c bioconda seqkit fastqc multiqc bbmap trimmomatic # Install kneaddata from Biobakery channel (for metagenomics) mamba install -c biobakery kneaddata 1.3 R Note # These tools are primarily used from the command line, but their output files # (e.g., FastQC or MultiQC reports) can be imported into R for downstream summarization. "],["how-do-i-obtain-example-microbiome-sequencing-data-for-analysis.html", "Q&A 2 How do I obtain example microbiome sequencing data for analysis? 2.1 Explanation 2.2 Shell Code 2.3 Python Note 2.4 R Note", " Q&A 2 How do I obtain example microbiome sequencing data for analysis? 2.1 Explanation Before performing any analysis, you need access to microbiome sequencing data. This data typically comes in the form of FASTQ files (either single-end or paired-end), which contain raw reads from amplicon sequencing. There are several sources for publicly available datasets: - QIIME2 Tutorials: Include curated sample data for testing pipelines - NCBI SRA / EBI ENA: Provide raw sequencing data from published studies - Qiita: A microbiome database for submitting and reusing 16S/18S/ITS data - Mock communities: Simulated or synthetic datasets used to benchmark tools This example uses the classic Moving Pictures tutorial dataset from QIIME2. 2.2 Shell Code # Download paired-end FASTQ data from QIIME2 tutorial wget https://data.qiime2.org/2024.2/tutorials/moving-pictures/emp-paired-end-sequences/barcodes.fastq.gz wget https://data.qiime2.org/2024.2/tutorials/moving-pictures/emp-paired-end-sequences/forward.fastq.gz wget https://data.qiime2.org/2024.2/tutorials/moving-pictures/emp-paired-end-sequences/reverse.fastq.gz 2.3 Python Note # Although QIIME2 is Python-based, raw sequencing data is usually downloaded externally. # Python/QIIME2 will be used later to import and process these FASTQ files. 2.4 R Note # Most raw sequencing workflows do not begin in R. However, after generating feature tables # from tools like QIIME2 or mothur, R will be used for downstream analysis and visualization. "],["how-do-i-process-raw-sequencing-data-into-a-feature-table-using-qiime2.html", "Q&A 3 How do I process raw sequencing data into a feature table using QIIME2? 3.1 Explanation 3.2 Shell Code (QIIME2 CLI) 3.3 Python Note", " Q&A 3 How do I process raw sequencing data into a feature table using QIIME2? 3.1 Explanation After obtaining your raw FASTQ data, the first analytical step is transforming it into a structured format for analysis — the feature table. This is a matrix of counts (samples × ASVs or OTUs). QIIME2 is a powerful, Python-based platform for this entire workflow. It uses .qza files (QIIME artifacts) to structure data at each step and generates a .qzv summary for inspection. This pipeline includes: - Importing FASTQ data - Demultiplexing reads - Denoising to generate ASVs using DADA2 or Deblur - Creating a feature table 3.2 Shell Code (QIIME2 CLI) # 1. Import paired-end reads qiime tools import \\ --type EMPPairedEndSequences \\ --input-path emp-paired-end-sequences \\ --output-path emp-paired-end-sequences.qza # 2. Demultiplex (barcode + sample mapping required) qiime demux emp-paired \\ --i-seqs emp-paired-end-sequences.qza \\ --m-barcodes-file sample-metadata.tsv \\ --m-barcodes-column BarcodeSequence \\ --o-per-sample-sequences demux.qza \\ --o-error-correction-details demux-details.qza # 3. Visualize quality qiime demux summarize \\ --i-data demux.qza \\ --o-visualization demux.qzv # 4. Denoise with DADA2 qiime dada2 denoise-paired \\ --i-demultiplexed-seqs demux.qza \\ --p-trim-left-f 0 \\ --p-trim-left-r 0 \\ --p-trunc-len-f 240 \\ --p-trunc-len-r 200 \\ --o-table table.qza \\ --o-representative-sequences rep-seqs.qza \\ --o-denoising-stats denoising-stats.qza 3.3 Python Note # Although QIIME2 is Python-based, its workflow is run via CLI. # Feature table (table.qza) can be exported and summarized later using Python or R. "],["how-do-i-process-raw-sequencing-data-into-a-feature-table-using-mothur.html", "Q&A 4 How do I process raw sequencing data into a feature table using Mothur? 4.1 Explanation 4.2 Shell Code 4.3 R Note 4.4 Python Note", " Q&A 4 How do I process raw sequencing data into a feature table using Mothur? 4.1 Explanation Mothur is an open-source software package for analyzing 16S rRNA gene sequences. It supports raw data preprocessing, OTU clustering, and taxonomic assignment. Its workflow is particularly popular for microbial community studies and works well with single- or paired-end FASTQ data. Mothur pipelines are usually run using command files or interactively within the Mothur console. Key steps include: - Merging paired-end reads - Quality filtering - Aligning and clustering reads into OTUs - Generating .shared (feature table) and .taxonomy files 4.2 Shell Code # Launch Mothur mothur # Inside Mothur console (example workflow) mothur &gt; make.file(inputdir=./raw_data, type=fastq, prefix=stability) mothur &gt; make.contigs(file=stability.files, processors=8) mothur &gt; screen.seqs(fasta=stability.trim.contigs.fasta, group=stability.contigs.groups, maxambig=0, maxlength=275) mothur &gt; unique.seqs(fasta=stability.trim.contigs.good.fasta) mothur &gt; count.seqs(name=stability.trim.contigs.good.names, group=stability.contigs.good.groups) mothur &gt; align.seqs(fasta=stability.trim.contigs.good.unique.fasta, reference=silva.seed_v138.align) mothur &gt; screen.seqs(...) mothur &gt; pre.cluster(...) mothur &gt; chimera.vsearch(...) mothur &gt; remove.seqs(...) mothur &gt; cluster.split(...) mothur &gt; make.shared(...) mothur &gt; classify.otu(...) 4.3 R Note # Mothur outputs a `.shared` file (feature/OTU table) and `.taxonomy` file. # These can be imported into R using packages like phyloseq or tidyverse for analysis. 4.4 Python Note # Mothur is not Python-based, but output files can be parsed with pandas or biom-format readers. "],["how-do-i-explore-and-summarize-a-microbiome-otu-table.html", "Q&A 5 How do I explore and summarize a microbiome OTU table? 5.1 Explanation 5.2 Python Code 5.3 R Code", " Q&A 5 How do I explore and summarize a microbiome OTU table? 5.1 Explanation After generating an OTU (or feature) table from raw sequencing data, it’s essential to inspect and summarize it before moving into alpha or beta diversity analysis. The OTU table is typically a matrix of samples × features (ASVs/OTUs), where each cell contains the abundance count of a feature in a sample. Key summary steps include: - Calculating sample richness (how many OTUs each sample contains) - Measuring OTU prevalence (in how many samples each OTU occurs) - Assessing abundance distribution (e.g., sparse vs dominant OTUs) - Identifying sparse or noisy features that may need filtering 5.2 Python Code import pandas as pd # Load OTU table (OTUs as rows, samples as columns) otu_df = pd.read_csv(&quot;data/otu_table.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) # Number of OTUs per sample (richness) sample_richness = (otu_df &gt; 0).sum(axis=0) # Number of samples per OTU (prevalence) otu_prevalence = (otu_df &gt; 0).sum(axis=1) # Distribution of total counts per OTU otu_abundance_summary = otu_df.sum(axis=1).describe() print(&quot;Sample Richness:&quot;, sample_richness.head()) print(&quot;OTU Prevalence:&quot;, otu_prevalence.head()) print(&quot;Abundance Summary:&quot;, otu_abundance_summary) 5.3 R Code otu_df &lt;- read.delim(&quot;data/otu_table.tsv&quot;, row.names = 1) # Sample richness: number of OTUs per sample colSums(otu_df &gt; 0) Sample_1 Sample_2 Sample_3 Sample_4 Sample_5 Sample_6 Sample_7 Sample_8 44 44 43 40 40 42 45 43 Sample_9 Sample_10 45 41 # OTU prevalence: number of samples each OTU appears in rowSums(otu_df &gt; 0) OTU_1 OTU_2 OTU_3 OTU_4 OTU_5 OTU_6 OTU_7 OTU_8 OTU_9 OTU_10 OTU_11 10 7 9 9 8 8 7 8 9 8 10 OTU_12 OTU_13 OTU_14 OTU_15 OTU_16 OTU_17 OTU_18 OTU_19 OTU_20 OTU_21 OTU_22 9 10 9 9 7 9 10 9 10 7 8 OTU_23 OTU_24 OTU_25 OTU_26 OTU_27 OTU_28 OTU_29 OTU_30 OTU_31 OTU_32 OTU_33 8 9 8 9 9 10 8 8 7 9 9 OTU_34 OTU_35 OTU_36 OTU_37 OTU_38 OTU_39 OTU_40 OTU_41 OTU_42 OTU_43 OTU_44 8 10 10 9 10 7 8 8 9 9 8 OTU_45 OTU_46 OTU_47 OTU_48 OTU_49 OTU_50 8 8 8 7 7 9 # Distribution of total counts per OTU summary(rowSums(otu_df)) Min. 1st Qu. Median Mean 3rd Qu. Max. 36.0 41.0 48.0 47.4 52.0 64.0 "],["how-do-i-filter-out-low-abundance-or-low-prevalence-otus.html", "Q&A 6 How do I filter out low-abundance or low-prevalence OTUs? 6.1 Explanation 6.2 Python Code 6.3 R Code", " Q&A 6 How do I filter out low-abundance or low-prevalence OTUs? 6.1 Explanation OTU tables are often sparse, with many OTUs occurring in only a few samples or at very low abundances. These low-abundance and low-prevalence OTUs can introduce noise, inflate diversity metrics, and complicate downstream analysis. Filtering such OTUs is a critical EDA step before diversity analysis or visualization. Common criteria include: - Prevalence: Removing OTUs that appear in fewer than X samples - Abundance: Removing OTUs with total counts below a threshold This step helps reduce dimensionality and improves interpretability. 6.2 Python Code import pandas as pd # Load OTU table otu_df = pd.read_csv(&quot;data/otu_table.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) # Filter: keep OTUs present in at least 3 samples otu_filtered = otu_df[(otu_df &gt; 0).sum(axis=1) &gt;= 3] # Further filter: keep OTUs with total count ≥ 10 otu_filtered = otu_filtered[otu_filtered.sum(axis=1) &gt;= 10] # Save filtered table otu_filtered.to_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;) 6.3 R Code otu_df &lt;- read.delim(&quot;data/otu_table.tsv&quot;, row.names = 1) # Filter OTUs with prevalence ≥ 3 samples keep_rows &lt;- rowSums(otu_df &gt; 0) &gt;= 3 otu_df &lt;- otu_df[keep_rows, ] # Further filter by total abundance ≥ 10 keep_abundant &lt;- rowSums(otu_df) &gt;= 10 otu_df_filtered &lt;- otu_df[keep_abundant, ] # Write filtered table write.table(otu_df_filtered, file = &quot;data/otu_table_filtered.tsv&quot;, sep = &quot;\\t&quot;) "],["how-do-i-visualize-total-otu-abundance-per-sample.html", "Q&A 7 How do I visualize total OTU abundance per sample? 7.1 Explanation 7.2 Python Code 7.3 R Code", " Q&A 7 How do I visualize total OTU abundance per sample? 7.1 Explanation Before diving into deeper microbiome comparisons, it’s helpful to visualize the sequencing depth — the total number of OTU counts per sample. This allows you to check: - Sample variability - Potential outliers - Overall library size distribution Using modern tools like ggplot2 in R or seaborn in Python helps create clearer, more elegant plots. 7.2 Python Code import pandas as pd import seaborn as sns import matplotlib.pyplot as plt # Load OTU table otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) # Prepare data total_counts = otu_df.sum(axis=0).reset_index() total_counts.columns = [&quot;Sample&quot;, &quot;Total_OTUs&quot;] # Plot plt.figure(figsize=(10, 5)) sns.barplot(data=total_counts, x=&quot;Sample&quot;, y=&quot;Total_OTUs&quot;, palette=&quot;viridis&quot;) plt.title(&quot;Total OTU Abundance Per Sample&quot;) plt.xticks(rotation=45) plt.ylabel(&quot;Total OTU Counts&quot;) plt.tight_layout() plt.show() 7.3 R Code library(tidyverse) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) otu_long &lt;- colSums(otu_df) %&gt;% enframe(name = &quot;Sample&quot;, value = &quot;Total_OTUs&quot;) ggplot(otu_long, aes(x = Sample, y = Total_OTUs)) + geom_col(fill = &quot;#0073C2FF&quot;) + labs(title = &quot;Total OTU Abundance Per Sample&quot;, y = &quot;Total OTU Counts&quot;) + theme_minimal(base_size = 13) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) "],["how-do-i-create-a-stacked-bar-plot-of-top-genera-across-samples.html", "Q&A 8 How do I create a stacked bar plot of top genera across samples? 8.1 Explanation 8.2 Python Code 8.3 R Code", " Q&A 8 How do I create a stacked bar plot of top genera across samples? 8.1 Explanation Stacked bar plots are widely used in microbiome studies to show relative abundance of microbial taxa across samples. This visual helps assess: - Community composition - Dominant vs rare genera - Variability between sample groups Here we simulate a relative abundance plot using the Genus column from the taxonomy file merged with the OTU table. 8.2 Python Code import pandas as pd import seaborn as sns import matplotlib.pyplot as plt # Load OTU table and taxonomy otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) tax_df = pd.read_csv(&quot;data/otu_taxonomy.tsv&quot;) # Merge taxonomy info (Genus) with OTU table merged = otu_df.merge(tax_df[[&quot;OTU_ID&quot;, &quot;Genus&quot;]], left_index=True, right_on=&quot;OTU_ID&quot;) melted = merged.drop(&quot;OTU_ID&quot;, axis=1).melt(id_vars=&quot;Genus&quot;, var_name=&quot;Sample&quot;, value_name=&quot;Abundance&quot;) # Summarize top 8 genera, lump rest as &#39;Other&#39; top_genera = melted.groupby(&quot;Genus&quot;)[&quot;Abundance&quot;].sum().nlargest(8).index melted[&quot;Genus&quot;] = melted[&quot;Genus&quot;].where(melted[&quot;Genus&quot;].isin(top_genera), &quot;Other&quot;) # Normalize per sample melted = melted.groupby([&quot;Sample&quot;, &quot;Genus&quot;])[&quot;Abundance&quot;].sum().reset_index() melted[&quot;RelativeAbundance&quot;] = melted.groupby(&quot;Sample&quot;)[&quot;Abundance&quot;].transform(lambda x: x / x.sum()) # Plot plt.figure(figsize=(12, 5)) sns.barplot(data=melted, x=&quot;Sample&quot;, y=&quot;RelativeAbundance&quot;, hue=&quot;Genus&quot;) plt.title(&quot;Stacked Barplot of Top Genera Across Samples&quot;) plt.ylabel(&quot;Relative Abundance&quot;) plt.xticks(rotation=45) plt.legend(bbox_to_anchor=(1.05, 1), loc=&quot;upper left&quot;) plt.tight_layout() plt.show() 8.3 R Code library(tidyverse) # Load OTU and taxonomy tables otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) tax_df &lt;- read.delim(&quot;data/otu_taxonomy.tsv&quot;) # Merge by rownames (OTUs) otu_df$OTU_ID &lt;- rownames(otu_df) merged_df &lt;- left_join(otu_df, tax_df, by = &quot;OTU_ID&quot;) # Convert to long format and summarize long_df &lt;- merged_df %&gt;% pivot_longer(cols = starts_with(&quot;Sample&quot;), names_to = &quot;Sample&quot;, values_to = &quot;Abundance&quot;) %&gt;% group_by(Sample, Genus) %&gt;% summarise(Abundance = sum(Abundance), .groups = &quot;drop&quot;) %&gt;% group_by(Sample) %&gt;% mutate(RelativeAbundance = Abundance / sum(Abundance)) # Keep top 8 genera top_genera &lt;- long_df %&gt;% group_by(Genus) %&gt;% summarise(Total = sum(RelativeAbundance), .groups = &quot;drop&quot;) %&gt;% top_n(8, Total) %&gt;% pull(Genus) long_df &lt;- long_df %&gt;% mutate(Genus = if_else(Genus %in% top_genera, Genus, &quot;Other&quot;)) # Plot ggplot(long_df, aes(x = Sample, y = RelativeAbundance, fill = Genus)) + geom_col() + theme_minimal(base_size = 13) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs(title = &quot;Stacked Barplot of Top Genera Across Samples&quot;, y = &quot;Relative Abundance&quot;) "],["how-do-i-visualize-alpha-diversity-richness-across-groups.html", "Q&A 9 How do I visualize alpha diversity (richness) across groups? 9.1 Explanation 9.2 Python Code 9.3 R Code", " Q&A 9 How do I visualize alpha diversity (richness) across groups? 9.1 Explanation Alpha diversity measures within-sample diversity — often captured by the number of observed OTUs or ASVs (richness). Visualizing alpha diversity across experimental groups (e.g., Control vs Treatment) helps detect differences in microbial complexity. Boxplots are commonly used for this purpose. To generate the plot, we: - Sum OTUs per sample - Merge with metadata - Group by condition (e.g., Treatment group) 9.2 Python Code import pandas as pd import seaborn as sns import matplotlib.pyplot as plt # Load OTU table and metadata otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) meta_df = pd.read_csv(&quot;data/sample_metadata.tsv&quot;, sep=&quot;\\t&quot;) # Compute richness richness = pd.DataFrame({ &quot;sample_id&quot;: otu_df.columns, &quot;richness&quot;: (otu_df &gt; 0).sum(axis=0).values }) # Merge with metadata merged = pd.merge(richness, meta_df, on=&quot;sample_id&quot;) # Plot plt.figure(figsize=(8, 5)) sns.boxplot(data=merged, x=&quot;group&quot;, y=&quot;richness&quot;, palette=&quot;Set2&quot;) sns.stripplot(data=merged, x=&quot;group&quot;, y=&quot;richness&quot;, color=&#39;black&#39;, alpha=0.5) plt.title(&quot;Alpha Diversity (Richness) by Group&quot;) plt.ylabel(&quot;Observed OTUs&quot;) plt.xlabel(&quot;Group&quot;) plt.tight_layout() plt.show() 9.3 R Code library(tidyverse) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) meta_df &lt;- read.delim(&quot;data/sample_metadata.tsv&quot;) # Compute richness richness &lt;- colSums(otu_df &gt; 0) richness_df &lt;- data.frame(sample_id = names(richness), richness = richness) # Merge with metadata merged &lt;- left_join(richness_df, meta_df, by = &quot;sample_id&quot;) # Plot ggplot(merged, aes(x = group, y = richness)) + geom_boxplot(fill = &quot;#00BFC4&quot;, alpha = 0.7) + geom_jitter(width = 0.1, color = &quot;black&quot;, alpha = 0.6) + theme_minimal(base_size = 13) + labs(title = &quot;Alpha Diversity (Richness) by Group&quot;, y = &quot;Observed OTUs&quot;, x = &quot;Group&quot;) "],["how-do-i-perform-ordination-e.g.-pca-to-visualize-sample-clustering.html", "Q&A 10 How do I perform ordination (e.g., PCA) to visualize sample clustering? 10.1 Explanation 10.2 Python Code 10.3 R Code", " Q&A 10 How do I perform ordination (e.g., PCA) to visualize sample clustering? 10.1 Explanation Ordination techniques like PCA, NMDS, or PCoA help reduce the complexity of high-dimensional OTU tables, making it easier to visualize sample relationships. These methods project samples into 2D or 3D based on similarity in microbial composition. Samples that cluster together share similar community profiles. In this example, we’ll perform PCA on centered log-ratio (CLR) transformed data — a common preprocessing step in microbiome compositional analysis. 10.2 Python Code import pandas as pd from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler import seaborn as sns import matplotlib.pyplot as plt # Load OTU and metadata otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0).T meta_df = pd.read_csv(&quot;data/sample_metadata.tsv&quot;, sep=&quot;\\t&quot;) # Replace 0s with pseudocount for log transformation otu_df += 1 otu_log = np.log(otu_df) # Standardize (optional) otu_scaled = StandardScaler().fit_transform(otu_log) # PCA pca = PCA(n_components=2) pca_result = pca.fit_transform(otu_scaled) pca_df = pd.DataFrame(pca_result, columns=[&quot;PC1&quot;, &quot;PC2&quot;]) pca_df[&quot;sample_id&quot;] = otu_df.index # Merge with metadata pca_df = pd.merge(pca_df, meta_df, on=&quot;sample_id&quot;) # Plot plt.figure(figsize=(8, 6)) sns.scatterplot(data=pca_df, x=&quot;PC1&quot;, y=&quot;PC2&quot;, hue=&quot;group&quot;, style=&quot;location&quot;, s=100) plt.title(&quot;PCA of Microbiome Samples&quot;) plt.xlabel(f&quot;PC1 ({pca.explained_variance_ratio_[0]:.2%})&quot;) plt.ylabel(f&quot;PC2 ({pca.explained_variance_ratio_[1]:.2%})&quot;) plt.tight_layout() plt.show() 10.3 R Code library(tidyverse) library(vegan) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) meta_df &lt;- read.delim(&quot;data/sample_metadata.tsv&quot;) # CLR transformation (log + pseudocount) otu_clr &lt;- log(otu_df + 1) otu_scaled &lt;- scale(t(otu_clr)) # samples as rows # PCA pca_res &lt;- prcomp(otu_scaled, center = TRUE, scale. = TRUE) pca_df &lt;- as.data.frame(pca_res$x[, 1:2]) pca_df$sample_id &lt;- rownames(pca_df) # Merge merged &lt;- left_join(pca_df, meta_df, by = &quot;sample_id&quot;) # Plot ggplot(merged, aes(x = PC1, y = PC2, color = group, shape = location)) + geom_point(size = 3, alpha = 0.8) + theme_minimal(base_size = 13) + labs(title = &quot;PCA of Microbiome Samples&quot;, x = &quot;PC1&quot;, y = &quot;PC2&quot;) "],["how-do-i-visualize-otu-or-genus-abundance-using-a-heatmap.html", "Q&A 11 How do I visualize OTU or Genus abundance using a heatmap? 11.1 Explanation 11.2 Python Code 11.3 R Code", " Q&A 11 How do I visualize OTU or Genus abundance using a heatmap? 11.1 Explanation Heatmaps are excellent for visualizing microbial abundance patterns across samples. They help identify: - Co-occurring OTUs or genera - Sample clusters with similar profiles - High- or low-abundance taxa patterns Heatmaps often include clustering on rows (features) and columns (samples), with scaling or log-transformation to improve interpretability. In this example, we visualize the top 20 most abundant OTUs across all samples. 11.2 Python Code import pandas as pd import seaborn as sns import matplotlib.pyplot as plt # Load OTU table otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) # Select top 20 OTUs by total abundance top_otus = otu_df.sum(axis=1).nlargest(20).index top_otu_df = otu_df.loc[top_otus] # Normalize (relative abundance per sample) rel_abund = top_otu_df.div(top_otu_df.sum(axis=0), axis=1) # Plot heatmap plt.figure(figsize=(10, 8)) sns.heatmap(rel_abund, cmap=&quot;YlGnBu&quot;, linewidths=0.5) plt.title(&quot;Heatmap of Top 20 OTUs (Relative Abundance)&quot;) plt.xlabel(&quot;Samples&quot;) plt.ylabel(&quot;OTUs&quot;) plt.tight_layout() plt.show() 11.3 R Code library(tidyverse) library(pheatmap) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) # Select top 20 OTUs by abundance top_otus &lt;- rowSums(otu_df) %&gt;% sort(decreasing = TRUE) %&gt;% head(20) %&gt;% names() top_otu_df &lt;- otu_df[top_otus, ] # Convert to relative abundance rel_abund &lt;- sweep(top_otu_df, 2, colSums(top_otu_df), FUN = &quot;/&quot;) # Plot heatmap pheatmap(rel_abund, color = colorRampPalette(c(&quot;white&quot;, &quot;#0073C2FF&quot;))(100), fontsize = 11, main = &quot;Heatmap of Top 20 OTUs (Relative Abundance)&quot;) "],["how-do-i-statistically-compare-otu-richness-between-groups.html", "Q&A 12 How do I statistically compare OTU richness between groups? 12.1 Explanation 12.2 Python Code 12.3 R Code", " Q&A 12 How do I statistically compare OTU richness between groups? 12.1 Explanation Once you’ve calculated alpha diversity (e.g., observed OTUs per sample), it’s common to test whether groups differ significantly. This can help you determine if an experimental condition affects microbial richness. Typical tests include: - T-test (for two groups, normally distributed data) - Wilcoxon rank-sum test (non-parametric) - ANOVA or Kruskal-Wallis (for 3+ groups) Here we demonstrate group comparison for richness using appropriate statistical tests. 12.2 Python Code import pandas as pd from scipy.stats import ttest_ind, mannwhitneyu # Load richness and metadata otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) meta_df = pd.read_csv(&quot;data/sample_metadata.tsv&quot;, sep=&quot;\\t&quot;) # Compute richness richness = pd.DataFrame({ &quot;sample_id&quot;: otu_df.columns, &quot;richness&quot;: (otu_df &gt; 0).sum(axis=0).values }) data = pd.merge(richness, meta_df, on=&quot;sample_id&quot;) # Split by group control = data[data[&quot;group&quot;] == &quot;Control&quot;][&quot;richness&quot;] treatment = data[data[&quot;group&quot;] == &quot;Treatment&quot;][&quot;richness&quot;] # T-test (assumes normality) t_stat, t_pval = ttest_ind(control, treatment) # Wilcoxon (non-parametric) w_stat, w_pval = mannwhitneyu(control, treatment) print(f&quot;T-test p-value: {t_pval:.4f}&quot;) print(f&quot;Wilcoxon test p-value: {w_pval:.4f}&quot;) 12.3 R Code library(tidyverse) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) meta_df &lt;- read.delim(&quot;data/sample_metadata.tsv&quot;) # Calculate richness richness &lt;- colSums(otu_df &gt; 0) richness_df &lt;- data.frame(sample_id = names(richness), richness = richness) merged &lt;- left_join(richness_df, meta_df, by = &quot;sample_id&quot;) # T-test t_test &lt;- t.test(richness ~ group, data = merged) # Wilcoxon test wilcox_test &lt;- wilcox.test(richness ~ group, data = merged) t_test$p.value [1] 0.2666018 wilcox_test$p.value [1] 0.2447901 "],["how-do-i-test-for-correlation-between-alpha-diversity-and-age.html", "Q&A 13 How do I test for correlation between alpha diversity and age? 13.1 Explanation 13.2 Python Code 13.3 R Code", " Q&A 13 How do I test for correlation between alpha diversity and age? 13.1 Explanation In many studies, you may want to examine whether microbial diversity is associated with continuous metadata like age, BMI, or pH. Correlation tests help assess linear or monotonic relationships between variables: - Pearson correlation: for linear relationships (assumes normality) - Spearman correlation: for monotonic (rank-based) associations (non-parametric) This Q&amp;A demonstrates testing correlation between richness and age. 13.2 Python Code import pandas as pd from scipy.stats import pearsonr, spearmanr # Load OTU and metadata otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) meta_df = pd.read_csv(&quot;data/sample_metadata.tsv&quot;, sep=&quot;\\t&quot;) # Compute richness richness = pd.DataFrame({ &quot;sample_id&quot;: otu_df.columns, &quot;richness&quot;: (otu_df &gt; 0).sum(axis=0).values }) data = pd.merge(richness, meta_df, on=&quot;sample_id&quot;) # Pearson correlation pearson_corr, pearson_pval = pearsonr(data[&quot;richness&quot;], data[&quot;age&quot;]) # Spearman correlation spearman_corr, spearman_pval = spearmanr(data[&quot;richness&quot;], data[&quot;age&quot;]) print(f&quot;Pearson r: {pearson_corr:.3f}, p = {pearson_pval:.4f}&quot;) print(f&quot;Spearman rho: {spearman_corr:.3f}, p = {spearman_pval:.4f}&quot;) 13.3 R Code library(tidyverse) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) meta_df &lt;- read.delim(&quot;data/sample_metadata.tsv&quot;) # Compute richness richness &lt;- colSums(otu_df &gt; 0) richness_df &lt;- data.frame(sample_id = names(richness), richness = richness) merged &lt;- left_join(richness_df, meta_df, by = &quot;sample_id&quot;) # Pearson correlation cor.test(merged$richness, merged$age, method = &quot;pearson&quot;) Pearson&#39;s product-moment correlation data: merged$richness and merged$age t = -0.099992, df = 8, p-value = 0.9228 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: -0.6504867 0.6078167 sample estimates: cor -0.03533044 # Spearman correlation cor.test(merged$richness, merged$age, method = &quot;spearman&quot;) Spearman&#39;s rank correlation rho data: merged$richness and merged$age S = 179.17, p-value = 0.8135 alternative hypothesis: true rho is not equal to 0 sample estimates: rho -0.08589604 "],["how-do-i-compare-alpha-diversity-across-3-or-more-groups.html", "Q&A 14 How do I compare alpha diversity across 3 or more groups? 14.1 Explanation 14.2 Python Code 14.3 R Code", " Q&A 14 How do I compare alpha diversity across 3 or more groups? 14.1 Explanation When comparing microbial richness across more than two groups, you can use: - ANOVA: if data are normally distributed - Kruskal-Wallis test: non-parametric alternative This Q&amp;A tests whether OTU richness differs by body location (e.g., gut, skin). 14.2 Python Code import pandas as pd from scipy.stats import f_oneway, kruskal # Load data otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) meta_df = pd.read_csv(&quot;data/sample_metadata.tsv&quot;, sep=&quot;\\t&quot;) # Compute richness richness = pd.DataFrame({ &quot;sample_id&quot;: otu_df.columns, &quot;richness&quot;: (otu_df &gt; 0).sum(axis=0).values }) data = pd.merge(richness, meta_df, on=&quot;sample_id&quot;) # Split richness by location groups = [group[&quot;richness&quot;].values for name, group in data.groupby(&quot;location&quot;)] # ANOVA f_stat, f_pval = f_oneway(*groups) # Kruskal-Wallis kw_stat, kw_pval = kruskal(*groups) print(f&quot;ANOVA p-value: {f_pval:.4f}&quot;) print(f&quot;Kruskal-Wallis p-value: {kw_pval:.4f}&quot;) 14.3 R Code library(tidyverse) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) meta_df &lt;- read.delim(&quot;data/sample_metadata.tsv&quot;) # Compute richness richness &lt;- colSums(otu_df &gt; 0) richness_df &lt;- data.frame(sample_id = names(richness), richness = richness) merged &lt;- left_join(richness_df, meta_df, by = &quot;sample_id&quot;) # ANOVA anova_res &lt;- aov(richness ~ location, data = merged) # Kruskal-Wallis kruskal_res &lt;- kruskal.test(richness ~ location, data = merged) summary(anova_res) Df Sum Sq Mean Sq F value Pr(&gt;F) location 1 2.5 2.5 0.676 0.435 Residuals 8 29.6 3.7 kruskal_res Kruskal-Wallis rank sum test data: richness by location Kruskal-Wallis chi-squared = 0.71553, df = 1, p-value = 0.3976 "],["how-do-i-test-for-differences-in-community-composition-using-permanova.html", "Q&A 15 How do I test for differences in community composition using PERMANOVA? 15.1 Explanation 15.2 Python Code 15.3 R Code", " Q&A 15 How do I test for differences in community composition using PERMANOVA? 15.1 Explanation PERMANOVA (Permutational Multivariate Analysis of Variance) is used to test whether beta diversity significantly differs between groups. It operates on a dissimilarity matrix (e.g., Bray-Curtis) and partitions variation based on experimental factors like treatment group or location. This Q&amp;A applies PERMANOVA to Bray-Curtis distances computed from OTU abundances. 15.2 Python Code import pandas as pd from skbio.diversity import beta_diversity from skbio.stats.distance import permanova from skbio import DistanceMatrix # Load data otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0).T meta_df = pd.read_csv(&quot;data/sample_metadata.tsv&quot;, sep=&quot;\\t&quot;) # Compute Bray-Curtis distance matrix bray_dm = beta_diversity(&quot;braycurtis&quot;, otu_df.values, ids=otu_df.index) # Format metadata meta_df = meta_df.set_index(&quot;sample_id&quot;).loc[otu_df.index] # Run PERMANOVA result = permanova(distance_matrix=bray_dm, grouping=meta_df[&quot;group&quot;], permutations=999) print(result) 15.3 R Code library(vegan) library(tidyverse) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) meta_df &lt;- read.delim(&quot;data/sample_metadata.tsv&quot;) # Bray-Curtis distance otu_t &lt;- t(otu_df) bray &lt;- vegdist(otu_t, method = &quot;bray&quot;) # Match metadata meta_df &lt;- meta_df %&gt;% filter(sample_id %in% rownames(otu_t)) %&gt;% column_to_rownames(&quot;sample_id&quot;) # Run PERMANOVA (adonis) adonis_res &lt;- adonis2(bray ~ group, data = meta_df, permutations = 999) adonis_res Permutation test for adonis under reduced model Permutation: free Number of permutations: 999 adonis2(formula = bray ~ group, data = meta_df, permutations = 999) Df SumOfSqs R2 F Pr(&gt;F) Model 1 0.03744 0.08118 0.7068 0.891 Residual 8 0.42380 0.91882 Total 9 0.46124 1.00000 "],["how-do-i-test-for-differential-abundance-of-otus-across-groups.html", "Q&A 16 How do I test for differential abundance of OTUs across groups? 16.1 Explanation 16.2 Python Code 16.3 R Code", " Q&A 16 How do I test for differential abundance of OTUs across groups? 16.1 Explanation Differential abundance analysis identifies OTUs that significantly differ between groups (e.g., Control vs Treatment). While tools like DESeq2 are used for RNA-seq and microbiome count data, simpler methods like: - Wilcoxon tests - t-tests - ANCOM / ALDEx2 (specialized tools) can also be used with filtered OTU data. Here we demonstrate how to test one OTU at a time between groups. 16.2 Python Code import pandas as pd from scipy.stats import mannwhitneyu # Load OTU table and metadata otu_df = pd.read_csv(&quot;data/otu_table_filtered.tsv&quot;, sep=&quot;\\t&quot;, index_col=0) meta_df = pd.read_csv(&quot;data/sample_metadata.tsv&quot;, sep=&quot;\\t&quot;).set_index(&quot;sample_id&quot;) otu_df = otu_df[meta_df.index] # ensure matching # Perform Wilcoxon test for each OTU results = [] for otu in otu_df.index: control = otu_df.loc[otu, meta_df[&quot;group&quot;] == &quot;Control&quot;] treatment = otu_df.loc[otu, meta_df[&quot;group&quot;] == &quot;Treatment&quot;] stat, pval = mannwhitneyu(control, treatment) results.append((otu, pval)) # Convert to DataFrame df_results = pd.DataFrame(results, columns=[&quot;OTU&quot;, &quot;p_value&quot;]) df_results[&quot;adjusted_p&quot;] = df_results[&quot;p_value&quot;] * len(df_results) # Bonferroni df_results.sort_values(&quot;p_value&quot;).head() 16.3 R Code library(tidyverse) otu_df &lt;- read.delim(&quot;data/otu_table_filtered.tsv&quot;, row.names = 1) meta_df &lt;- read.delim(&quot;data/sample_metadata.tsv&quot;) # Ensure sample order matches otu_df &lt;- otu_df[, meta_df$sample_id] # Run Wilcoxon test for each OTU results &lt;- apply(otu_df, 1, function(x) { group &lt;- meta_df$group test &lt;- wilcox.test(x[group == &quot;Control&quot;], x[group == &quot;Treatment&quot;]) return(test$p.value) }) df_results &lt;- data.frame(OTU = rownames(otu_df), p_value = results) df_results$adjusted_p &lt;- p.adjust(df_results$p_value, method = &quot;bonferroni&quot;) head(df_results[order(df_results$p_value), ]) OTU p_value adjusted_p OTU_14 OTU_14 0.01962441 0.9812207 OTU_37 OTU_37 0.05855263 1.0000000 OTU_38 OTU_38 0.11049202 1.0000000 OTU_16 OTU_16 0.13262225 1.0000000 OTU_26 OTU_26 0.16123759 1.0000000 OTU_9 OTU_9 0.19882894 1.0000000 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
